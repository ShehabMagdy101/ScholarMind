{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4ad967",
   "metadata": {},
   "source": [
    "- input: PDF file\n",
    "- output: Vector DB representation\n",
    "\n",
    "Steps:\n",
    "1. Load & Parse PDF\n",
    "2. Text splitting\n",
    "3. Embedding\n",
    "4. Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a3ae1",
   "metadata": {},
   "source": [
    "## 0. Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ab23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install arxiv\n",
    "%pip install langchain\n",
    "%pip install pypdf\n",
    "%pip install langchain_community\n",
    "%pip install cohere\n",
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9583fda",
   "metadata": {},
   "source": [
    "## 1. PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c17fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheha\\AppData\\Local\\Temp\\ipykernel_11540\\2065310362.py:13: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  paper = next(search.results())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2510.18234 to paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# PDF File sample\n",
    "import arxiv\n",
    "\n",
    "def download_arxiv_doi(doi, save_path=\"paper.pdf\"):\n",
    "    '''\n",
    "    download only arxiv papers\n",
    "    '''\n",
    "    if not doi.startswith(\"10.48550/arXiv.\"):\n",
    "        raise Exception(\"Not an arXiv DOI.\")\n",
    "    \n",
    "    arxiv_id = doi.split(\"arXiv.\")[-1]\n",
    "    search = arxiv.Search(id_list=[arxiv_id])\n",
    "    paper = next(search.results())\n",
    "    paper.download_pdf(filename=save_path)\n",
    "    print(f\"Downloaded {arxiv_id} to {save_path}\")\n",
    "\n",
    "# Example:\n",
    "download_arxiv_doi(\"10.48550/arXiv.2510.18234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f244138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Parser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "llm_loader = PyPDFLoader(\"paper.pdf\")\n",
    "pages = llm_loader.load_and_split()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df650ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pikepdf 8.15.1',\n",
       " 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)',\n",
       " 'creationdate': '',\n",
       " 'author': 'Haoran Wei; Yaofeng Sun; Yukun Li',\n",
       " 'doi': 'https://doi.org/10.48550/arXiv.2510.18234',\n",
       " 'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1',\n",
       " 'title': 'DeepSeek-OCR: Contexts Optical Compression',\n",
       " 'trapped': '/False',\n",
       " 'arxivid': 'https://arxiv.org/abs/2510.18234v1',\n",
       " 'source': 'paper.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 3,\n",
       " 'page_label': '4'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[3].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2b973",
   "metadata": {},
   "source": [
    "## 2. Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c15866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=300,  # configurable variable\n",
    "    length_function = len,\n",
    "    chunk_overlap=50, # configurable variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1928bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "metadatas = []\n",
    "for page in pages:\n",
    "    documents.append(page.page_content)\n",
    "    metadatas.append(page.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771844d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents(documents, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed6923a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf01aa3",
   "metadata": {},
   "source": [
    "## 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35dd2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "env_values = dotenv_values('app.env')\n",
    "cohere_api_key = env_values['COHERE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "embedding_llm = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c37f2a",
   "metadata": {},
   "source": [
    "## 4. Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vector_db = FAISS.from_documents(chunks, embedding_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1326706",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is Context Optical Compression?\"\n",
    "similar_docs = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bee71cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components,\n",
      "data engineering, and training skills.\n",
      "3.2. DeepEncoder\n",
      "To explore the feasibility of contexts optical compression, we need a vision encoder with the\n",
      "following features: 1.Capable of processing high resolutions; 2.Low activation at high resolutions;\n",
      "3.Few vision tokens; 4.Support for mul\n"
     ]
    }
   ],
   "source": [
    "print(similar_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "309d64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_dir = \"faiss_vector_data\"\n",
    "vector_db.save_local(save_to_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
